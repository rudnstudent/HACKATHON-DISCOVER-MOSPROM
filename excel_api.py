#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excel -> API (POST). –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:
organizations, financial-indicators, property-land, addresses, production,
investment-export, support, company-sizes, industries, okveds, taxes, contacts
"""
import sys, re, json, math
import pandas as pd
import requests
from datetime import datetime
from typing import Any, Dict, Optional, Tuple, List

# ========= –ù–ê–°–¢–†–û–ô–ö–ò =========
API_BASE = "http://localhost:5000/api"
TIMEOUT = 30
VERIFY_SSL = False

session = requests.Session()
session.headers.update({"Content-Type": "application/json"})
session.verify = VERIFY_SSL

# ========= –•–ï–õ–ü–ï–†–´ –¢–ò–ü–û–í =========
def to_null(v: Any) -> Any:
    if v is None:
        return None
    try:
        if pd.isna(v): return None
    except Exception:
        pass
    if isinstance(v, str):
        s = v.strip()
        if s == "" or s.lower() in {"nan","none","null","–Ω/–¥","–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö","‚Äî","-"}:
            return None
        return s
    return v

def to_bool(v: Any) -> Optional[bool]:
    v = to_null(v)
    if v is None: return None
    if isinstance(v, bool): return v
    s = str(v).strip().lower()
    t = {"true","1","yes","y","–¥–∞","–∏—Å—Ç–∏–Ω–∞","–≤–µ—Ä–Ω–æ","–µ—Å—Ç—å","ok","–æ–∫"}
    f = {"false","0","no","n","–Ω–µ—Ç","–ª–æ–∂—å","–Ω–µ–≤–µ—Ä–Ω–æ"}
    if s in t: return True
    if s in f: return False
    return None

_num_clean_re = re.compile(r"[^\d\.\,\-]+")

def to_float(v: Any) -> Optional[float]:
    v = to_null(v)
    if v is None: return None
    if isinstance(v, (int,float)) and not isinstance(v, bool):
        return float(v)
    s = str(v)
    s = _num_clean_re.sub("", s).replace(" ", "").replace("\u00A0","").replace(",", ".")
    try:
        if s in {"", ".", "-", "-.", ".-"}: return None
        return float(s)
    except Exception:
        return None

def to_int(v: Any) -> Optional[int]:
    f = to_float(v)
    if f is None or (isinstance(f,float) and math.isnan(f)): return None
    try:
        return int(round(f))
    except Exception:
        return None

def normalize_inn(v: Any) -> Optional[str]:
    s = to_null(v)
    if s is None: return None
    digits = re.sub(r"\D+", "", str(s))
    return digits[:12] if digits else None

def pick(row: pd.Series, *cols: str) -> Any:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–∞–±–æ—Ä–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫."""
    for col in cols:
        if col in row.index:
            val = to_null(row[col])
            if val is not None:
                return val
    return None

def collect_year_data(row: pd.Series, keyword: str) -> Dict[str, Any]:
    """–ò—â–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º –∏ –≥–æ–¥–æ–º –≤ –∫–æ–Ω—Ü–µ."""
    result = {}
    for col in row.index:
        if keyword in col:
            parts = col.strip().split()
            year = parts[-1]
            if year.isdigit() and len(year) > 1:
                result[year] = to_null(row[col])
    return result or None

# ========= PAYLOAD BUILDERS (—Ç–æ—á–Ω–æ –ø–æ–¥ columns_metadata) =========
def build_organization_payload(row: pd.Series) -> Dict[str, Any]:
    return {
        "inn": normalize_inn(pick(row, "–ò–ù–ù")),
        "name": pick(row, "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"),
        "full_name": pick(row, "–ü–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"),
        "spark_status": pick(row, "–°—Ç–∞—Ç—É—Å –°–ü–ê–†–ö"),
        "internal_status": pick(row, "–°—Ç–∞—Ç—É—Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π"),
        "final_status": pick(row, "–°—Ç–∞—Ç—É—Å –ò–¢–û–ì"),
        "registry_addition_date": pick(row, "–î–∞—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä"),
        "registration_date": pick(row, "–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"),
        "manager_name": pick(row, "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å"),
        "website": pick(row, "–°–∞–π—Ç"),
        "email": pick(row, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞"),
        "general_info": pick(row, "–û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"),
        "head_organization": pick(row, "–ì–æ–ª–æ–≤–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è", "–ì–æ–ª–æ–≤–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)"),
        "head_organization_inn": normalize_inn(pick(row, "–ò–ù–ù –≥–æ–ª–æ–≤–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏")),
        "head_organization_relation_type": pick(row, "–¢–∏–ø —Å–≤—è–∑–∏ —Å –≥–æ–ª–æ–≤–Ω–æ–π"),
    }

def build_financial_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    revenue = collect_year_data(row, "–í—ã—Ä—É—á–∫–∞ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è")
    profit = collect_year_data(row, "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å")
    emp_total = collect_year_data(row, "–°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ (–≤—Å–µ–≥–æ –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏)")
    payroll_total = collect_year_data(row, "–§–æ–Ω–¥ –æ–ø–ª–∞—Ç—ã —Ç—Ä—É–¥–∞ –≤—Å–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏")
    # –î–æ–ø. –ø–æ–ª—è –æ—Å—Ç–∞–≤–ª—è–µ–º None, —Ç.–∫. –∏—Ö –Ω–µ—Ç –≤ Excel
    years = set()
    for d in (revenue, profit, emp_total, payroll_total):
        if d: years.update(d.keys())
    out = []
    for y in sorted(years):
        out.append({
            "organization_id": organization_id,
            "year": int(y),
            "revenue": to_float(revenue.get(y)) if revenue else None,
            "net_profit": to_float(profit.get(y)) if profit else None,
            "employee_count": to_int(emp_total.get(y)) if emp_total else None,
            "employee_count_moscow": None,
            "payroll_all_employees": to_float(payroll_total.get(y)) if payroll_total else None,
            "payroll_moscow_employees": None,
            "avg_salary_all_employees": None,
            "avg_salary_moscow_employees": None,
        })
    return out

def build_property_land_payload(row: pd.Series, organization_id: int) -> Dict[str, Any]:
    return {
        "organization_id": organization_id,
        "land_cadastral_number": pick(row, "–ö–∞–¥–∞—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä –ó–£"),
        "land_area": to_float(pick(row, "–ü–ª–æ—â–∞–¥—å –ó–£", "–ü–ª–æ—â–∞–¥—å –ó–£ (–≥–∞)")),
        "land_use_type": pick(row, "–í–∏–¥ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ó–£"),
        "land_ownership_type": pick(row, "–í–∏–¥ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –ó–£"),
        "land_owner": pick(row, "–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫ –ó–£"),
        "building_cadastral_number": pick(row, "–ö–∞–¥–∞—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä –û–ö–°–∞"),
        "building_area": to_float(pick(row, "–ü–ª–æ—â–∞–¥—å –û–ö–°–æ–≤", "–ü–ª–æ—â–∞–¥—å –û–ö–°–æ–≤ (–∫–≤.–º)")),
        "building_use_type": pick(row, "–í–∏–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –û–ö–°–æ–≤"),
        "building_type_purpose": pick(row, "–¢–∏–ø/–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –û–ö–°–æ–≤"),
        "building_ownership_type": pick(row, "–í–∏–¥ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –û–ö–°–æ–≤"),
        "building_owner": pick(row, "–°–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫ –û–ö–°–æ–≤"),
        "production_area": to_float(pick(row, "–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å")),
    }

def build_address_payload(row: pd.Series, organization_id: int) -> Dict[str, Any]:
    return {
        "organization_id": organization_id,
        "address_type": None,  # –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å "legal"/"production" –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏
        "full_address": pick(row, "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å", "–ê–¥—Ä–µ—Å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", "–ê–¥—Ä–µ—Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø–ª–æ—â–∞–¥–∫–∏"),
        "latitude": to_float(pick(row, "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (—à–∏—Ä–æ—Ç–∞)")),
        "longitude": to_float(pick(row, "–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–¥–æ–ª–≥–æ—Ç–∞)")),
        "district": pick(row, "–û–∫—Ä—É–≥"),
        "area": pick(row, "–†–∞–π–æ–Ω"),
    }

def infer_year_for_production(row: pd.Series) -> int:
    revenue = collect_year_data(row, "–í—ã—Ä—É—á–∫–∞ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è")
    years = [int(y) for y in (revenue or {}).keys() if y.isdigit()]
    return max(years) if years else datetime.now().year

def build_production_payload(row: pd.Series, organization_id: int) -> Dict[str, Any]:
    codes_raw = pick(row, "–ü–µ—Ä–µ—á–µ–Ω—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –ø–æ –∫–æ–¥–∞–º –û–ö–ü–î 2")
    okpd2_flat = None
    if isinstance(codes_raw, str):
        parts = [c.strip() for c in codes_raw.replace(",", ";").split(";") if c.strip()]
        okpd2_flat = "; ".join(parts) if parts else None
    return {
        "year": infer_year_for_production(row),
        "organization_id": organization_id,
        "manufactured_products": pick(row, "–ü—Ä–æ–∏–∑–≤–æ–¥–∏–º–∞—è –ø—Ä–æ–¥—É–∫—Ü–∏—è"),
        "standardized_products": pick(row, "–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–¥—É–∫—Ü–∏—è"),
        "product_names": pick(row, "–ù–∞–∑–≤–∞–Ω–∏–µ (–≤–∏–¥—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏)"),
        "okpd2_products": okpd2_flat,
        "product_types_segments": pick(row, "–°–µ–≥–º–µ–Ω—Ç—ã/—Ç–∏–ø—ã –ø—Ä–æ–¥—É–∫—Ü–∏–∏"),
        "product_catalog": pick(row, "–ö–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ (URL)", "–ö–∞—Ç–∞–ª–æ–≥ –ø—Ä–æ–¥—É–∫—Ü–∏–∏"),
        "government_order": to_bool(pick(row, "–ù–∞–ª–∏—á–∏–µ –≥–æ—Å–∑–∞–∫–∞–∑–∞")),
        "production_capacity_utilization": pick(row, "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ—â–Ω–æ—Å—Ç–µ–π, %"),
        "export_supplies": to_bool(pick(row, "–ù–∞–ª–∏—á–∏–µ –ø–æ—Å—Ç–∞–≤–æ–∫ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç")),
        "export_volume_previous_year": to_float(pick(row, "–û–±—ä–µ–º —ç–∫—Å–ø–æ—Ä—Ç–∞ (–º–ª–Ω.—Ä—É–±.) –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥–æ–¥")),
        "export_countries": (
            "; ".join([s.strip() for s in pick(row, "–ü–µ—Ä–µ—á–µ–Ω—å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤ –∫—É–¥–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –ø—Ä–æ–¥—É–∫—Ü–∏—è").split(";")])
            if isinstance(pick(row, "–ü–µ—Ä–µ—á–µ–Ω—å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤ –∫—É–¥–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –ø—Ä–æ–¥—É–∫—Ü–∏—è"), str) else None
        ),
        "tn_ved_code": pick(row, "–ö–æ–¥ –¢–ù –í–≠–î"),
    }

def build_investment_export_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    invest = collect_year_data(row, "–û–±—ä–µ–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –ú–æ—Å–∫–≤—ã") or collect_year_data(row, "–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –ú–æ—Å–∫–≤—ã")
    export = collect_year_data(row, "–û–±—ä–µ–º —ç–∫—Å–ø–æ—Ä—Ç–∞") or collect_year_data(row, "–≠–∫—Å–ø–æ—Ä—Ç, –º–ª–Ω")
    years = set()
    for d in (invest, export):
        if d: years.update(d.keys())
    out = []
    for y in sorted(years):
        out.append({
            "organization_id": organization_id,
            "year": int(y),
            "moscow_investments": to_float(invest.get(y)) if invest else None,
            "export_volume": to_float(export.get(y)) if export else None,
        })
    return out

def build_support_payload(row: pd.Series, organization_id: int) -> Dict[str, Any]:
    return {
        "organization_id": organization_id,
        "support_data": pick(row, "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ (–æ–ø–∏—Å–∞–Ω–∏–µ)", "–ü–æ–¥–¥–µ—Ä–∂–∫–∞/–º–µ—Ä—ã"),
        "special_status": pick(row, "–°–ø–µ—Ü—Å—Ç–∞—Ç—É—Å", "–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å"),
        "platform_final": pick(row, "–ü–ª–æ—â–∞–¥–∫–∞ –∏—Ç–æ–≥"),
        "moscow_support_received": to_bool(pick(row, "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ú–æ—Å–∫–≤—ã –ø–æ–ª—É—á–µ–Ω–∞", "–ü–æ–ª—É—á–∞–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –æ—Ç –ú–æ—Å–∫–≤—ã")),
        "system_forming_enterprise": to_bool(pick(row, "–°–∏—Å—Ç–µ–º–æ–æ–±—Ä–∞–∑—É—é—â–µ–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ")),
        "sme_status": pick(row, "–°—Ç–∞—Ç—É—Å –ú–°–ü"),
    }

def build_company_sizes_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    size_final = collect_year_data(row, "–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è (–∏—Ç–æ–≥)")
    size_by_employees = collect_year_data(row, "–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è (–ø–æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏)")
    size_by_revenue = collect_year_data(row, "–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è (–ø–æ –≤—ã—Ä—É—á–∫–µ)")
    years = set()
    for d in (size_final, size_by_employees, size_by_revenue):
        if d: years.update(d.keys())
    out = []
    if not years and pick(row, "–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è (–∏—Ç–æ–≥)"):
        # –±–µ–∑–≥–æ–¥–æ–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî –∑–∞–ø–∏—à–µ–º –æ–¥–∏–Ω —Ä–∞–∑ —Å —Ç–µ–∫—É—â–∏–º –≥–æ–¥–æ–º
        years = {str(datetime.now().year)}
    for y in sorted(years):
        out.append({
            "organization_id": organization_id,
            "year": int(y),
            "size_final": (size_final or {}).get(y) or pick(row, "–†–∞–∑–º–µ—Ä –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è (–∏—Ç–æ–≥)"),
            "size_by_employees": (size_by_employees or {}).get(y),
            "size_by_revenue": (size_by_revenue or {}).get(y),
        })
    return out

def build_industries_payload(row: pd.Series, organization_id: int) -> Dict[str, Any]:
    return {
        "organization_id": organization_id,
        "main_industry": pick(row, "–û—Å–Ω–æ–≤–Ω–∞—è –æ—Ç—Ä–∞—Å–ª—å"),
        "main_subindustry": pick(row, "–ü–æ–¥–æ—Ç—Ä–∞—Å–ª—å (–û—Å–Ω–æ–≤–Ω–∞—è)"),
        "additional_industry": pick(row, "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç—Ä–∞—Å–ª—å"),
        "additional_subindustry": pick(row, "–ü–æ–¥–æ—Ç—Ä–∞—Å–ª—å (–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è)"),
        "industry_presentations": pick(row, "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –æ—Ç—Ä–∞—Å–ª–∏", "–°—Å—ã–ª–∫–∏/–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –æ—Ç—Ä–∞—Å–ª–∏"),
        "industry_by_spark": pick(row, "–û—Ç—Ä–∞—Å–ª—å –ø–æ –°–ü–ê–†–ö", "–û—Å–Ω–æ–≤–Ω–æ–π –û–ö–í–≠–î (–°–ü–ê–†–ö)"),
    }

def build_okveds_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    out = []
    # –û—Å–Ω–æ–≤–Ω–æ–π –û–ö–í–≠–î (–°–ü–ê–†–ö)
    main_code = pick(row, "–û—Å–Ω–æ–≤–Ω–æ–π –û–ö–í–≠–î (–°–ü–ê–†–ö)")
    main_desc = pick(row, "–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–º—É –û–ö–í–≠–î (–°–ü–ê–†–ö)")
    if main_code or main_desc:
        out.append({
            "organization_id": organization_id,
            "okved_type": "main_spark",
            "code": main_code,
            "description": main_desc
        })
    # –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –û–ö–í–≠–î
    prod_code = pick(row, "–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –û–ö–í–≠–î")
    prod_desc = pick(row, "–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–º—É –û–ö–í–≠–î")
    if prod_code or prod_desc:
        out.append({
            "organization_id": organization_id,
            "okved_type": "production",
            "code": prod_code,
            "description": prod_desc
        })
    return out

def build_taxes_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞–ª–æ–≥–∏ –ø–æ –≥–æ–¥–∞–º
    moscow_taxes = collect_year_data(row, "–ù–∞–ª–æ–≥–∏ –≤ –±—é–¥–∂–µ—Ç –ú–æ—Å–∫–≤—ã")
    profit_tax = collect_year_data(row, "–ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å")
    property_tax = collect_year_data(row, "–ù–∞–ª–æ–≥ –Ω–∞ –∏–º—É—â–µ—Å—Ç–≤–æ")
    land_tax = collect_year_data(row, "–ó–µ–º–µ–ª—å–Ω—ã–π –Ω–∞–ª–æ–≥")
    personal_income_tax = collect_year_data(row, "–ù–î–§–õ")
    transport_tax = collect_year_data(row, "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π –Ω–∞–ª–æ–≥")
    other_taxes = collect_year_data(row, "–ü—Ä–æ—á–∏–µ –Ω–∞–ª–æ–≥–∏")
    excise_taxes = collect_year_data(row, "–ê–∫—Ü–∏–∑—ã")

    years = set()
    for d in (moscow_taxes, profit_tax, property_tax, land_tax, personal_income_tax, transport_tax, other_taxes, excise_taxes):
        if d: years.update(d.keys())

    out = []
    for y in sorted(years):
        out.append({
            "organization_id": organization_id,
            "year": int(y),
            "moscow_taxes": to_float((moscow_taxes or {}).get(y)),
            "profit_tax": to_float((profit_tax or {}).get(y)),
            "property_tax": to_float((property_tax or {}).get(y)),
            "land_tax": to_float((land_tax or {}).get(y)),
            "personal_income_tax": to_float((personal_income_tax or {}).get(y)),
            "transport_tax": to_float((transport_tax or {}).get(y)),
            "other_taxes": to_float((other_taxes or {}).get(y)),
            "excise_taxes": to_float((excise_taxes or {}).get(y)),
        })
    return out

def build_contacts_payloads(row: pd.Series, organization_id: int) -> List[Dict[str, Any]]:
    # –ü—Ä–æ—Å—Ç–æ–π –∫–µ–π—Å: –æ–¥–∏–Ω –∫–æ–Ω—Ç–∞–∫—Ç –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–ª–µ–π
    contact_name = pick(row, "–ö–æ–Ω—Ç–∞–∫—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏", "–ö–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ –ª–∏—Ü–æ", "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å")
    phone = pick(row, "–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞", "–¢–µ–ª–µ—Ñ–æ–Ω")
    email = pick(row, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞", "–ü–æ—á—Ç–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞", "Email")
    out = []
    if contact_name or phone or email:
        out.append({
            "organization_id": organization_id,
            "contact_type": pick(row, "–¢–∏–ø –∫–æ–Ω—Ç–∞–∫—Ç–∞") or "general",
            "name": contact_name,
            "phone": phone,
            "email": email,
            "management_email": pick(row, "–ü–æ—á—Ç–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"),
        })
    return out

# ========= HTTP =========
def post_json(path: str, payload: Dict[str, Any]) -> Tuple[int, Dict[str, Any]]:
    url = f"{API_BASE.rstrip('/')}/{path.lstrip('/')}"
    resp = session.post(url, data=json.dumps(payload, ensure_ascii=False).encode("utf-8"), timeout=TIMEOUT)
    try:
        body = resp.json()
    except Exception:
        body = {"raw": resp.text}
    ok = resp.status_code in (200, 201)
    print(f"{'‚úÖ' if ok else '‚ùå'} POST {url} -> {resp.status_code} | {('id='+str(body.get('item').get('id'))) if ok else body}")
    return resp.status_code, body

# ========= –¶–ï–ü–û–ß–ö–ê –î–õ–Ø –û–î–ù–û–ô –°–¢–†–û–ö–ò =========
def upsert_row(row: pd.Series):
    # 1) organizations
    org = build_organization_payload(row)
    if not org["inn"] or not org["name"]:
        print("‚õî –ü—Ä–æ–ø—É—Å–∫: –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è inn/name –ø—É—Å—Ç—ã")
        return
    st, body = post_json("/organizations", org)
    if st not in (200, 201):
        print("‚õî –ù–µ —Å–æ–∑–¥–∞–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ü–µ–ø–æ—á–∫–∏")
        return

    org_id = body["item"]["id"]

    # 2) financial-indicators (–º–Ω–æ–≥–æ)
    for fi in build_financial_payloads(row, org_id):
        post_json("/financial-indicators", fi)

    # 3) property-land (1)
    post_json("/property-land", build_property_land_payload(row, org_id))

    # 4) addresses (1)
    post_json("/addresses", build_address_payload(row, org_id))

    # 5) production (1)
    post_json("/production", build_production_payload(row, org_id))

    # 6) investment-export (–º–Ω–æ–≥–æ)
    for inv in build_investment_export_payloads(row, org_id):
        post_json("/investment-export", inv)

    # 7) support (1)
    post_json("/support", build_support_payload(row, org_id))

    # 8) company-sizes (–º–Ω–æ–≥–æ/–∏–ª–∏ 1 –±–µ–∑ –≥–æ–¥–æ–≤—ã—Ö –ø–æ–ª–µ–π)
    for cs in build_company_sizes_payloads(row, org_id):
        post_json("/company-sizes", cs)

    # 9) industries (1)
    post_json("/industries", build_industries_payload(row, org_id))

    # 10) okveds (0..2)
    for okv in build_okveds_payloads(row, org_id):
        post_json("/okveds", okv)

    # 11) taxes (–º–Ω–æ–≥–æ)
    for tx in build_taxes_payloads(row, org_id):
        post_json("/taxes", tx)

    # 12) contacts (0..1)
    for c in build_contacts_payloads(row, org_id):
        post_json("/contacts", c)

# ========= MAIN =========
def excel_to_api(excel_path: str):
    print(excel_path)
    try:
        df = pd.read_excel(excel_path, dtype=str)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return 0
    df.columns = [str(c).strip().replace("\ufeff", "") for c in df.columns]
    if df.empty:
        print("–§–∞–π–ª –ø—É—Å—Ç")
        return 0

    print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} –∑–∞–ø–∏—Å–µ–π")

    processed_count = 0
    for i, row in df.iterrows():
        print(f"\nüìÑ –°—Ç—Ä–æ–∫–∞ {i+1}/{len(df)}")
        try:
            upsert_row(row)
            processed_count += 1
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {i+1}: {e}")
            continue
    
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {processed_count}")
    return processed_count
